{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore SVD based word embedding\n",
    "\n",
    "This notebook explores word embeddings that are based on SVD of a possibly transformed word-context matrix. Starting with the raw matrix `counts`\n",
    "\n",
    "- possilby transform `counts` (e.g. log data, do PPMI transform, normalize rows)\n",
    "- compute SVD of new matrix\n",
    "- explore word embeddings e.g. scores plots, word similarity\n",
    "- explore loadings\n",
    "\n",
    "The material in this notebook is covered in chapters 15/16 of SLP3\n",
    "- https://web.stanford.edu/~jurafsky/slp3/15.pdf\n",
    "- https://web.stanford.edu/~jurafsky/slp3/16.pdf\n",
    "\n",
    "\n",
    "## data\n",
    "\n",
    "The github repo comes with a small data set pre computed (from a random sample of 1000 court cases). You can download larger data files from https://drive.google.com/open?id=0B40b05f-8LWtVGsybWw4OTVyV00 then place them in the data/ folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import heapq\n",
    "\n",
    "from scipy.sparse.linalg import svds, norm\n",
    "from scipy.sparse import diags, csr_matrix, dok_matrix\n",
    "\n",
    "# import local code files\n",
    "import sys, os\n",
    "sys.path.append(os.getcwd() + '/code/')\n",
    "\n",
    "# working with word embeddings\n",
    "from save import load_vocabulary, load_matrix\n",
    "from ppmi import calc_ppmi\n",
    "from word_similarity import similarity, closest, vec, angle_between, word_angles\n",
    "from transform_counts import remove_zero_count_words, normalize_rows\n",
    "\n",
    "\n",
    "# exploring/visualizing scores/loadings\n",
    "from scores_viz import scores_plot, filter_scores\n",
    "from explore_loadings import top_loading_components, top_loading_words, top_loading_words_df\n",
    "\n",
    "# only import this if you have plot.ly installed\n",
    "# from viz_plotly import interactive_scores_plot\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2i, i2w = load_vocabulary('data/vocab_small_ex.txt')\n",
    "co_counts = load_matrix('data/co_counts_small_ex')\n",
    "word_counts = np.load('data/word_counts_small_ex.npy')\n",
    "\n",
    "# # uncomment this code if you have the larger data file\n",
    "# w2i, i2w = load_vocabulary('data_no_github/vocab_10000.txt')\n",
    "# co_counts = load_matrix('data_no_github/co_counts_10000')\n",
    "# word_counts = np.load('data_no_github/word_counts_10000.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<39424x39424 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 11250370 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transform counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalized row by row norms\n",
    "co_counts_normed = diags(1.0/norm(co_counts, axis=1)) * co_counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "co_counts_log = co_counts.copy()\n",
    "co_counts_log.data = np.log(1 + co_counts.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppmi = calc_ppmi(co_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD of counts matrix\n",
    "\n",
    "If $X \\in \\mathbb{R}^{n \\times d}$ is a data matrix with the n observations on rows then the rank K SVD is given by\n",
    "$$X \\approx U D V^T$$\n",
    "where $U \\in \\mathbb{R}^{n \\times K}$ is the matrix of normalized scores and  $V \\in \\mathbb{R}^{d \\times K}$ is the matrix of loadings.\n",
    "\n",
    "If X is a word-context matrix then U (or UD) gives a word embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.9 s, sys: 194 ms, total: 11.1 s\n",
      "Wall time: 2.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "k = 10\n",
    "\n",
    "normed_scores, sing_vals, loadings = svds(co_counts_normed, k)\n",
    "\n",
    "loadings = loadings.T\n",
    "un_normed_scores = normed_scores * sing_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the word embedding that is used in the rest of the script\n",
    "embedding = un_normed_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore word embedding (scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_plot(embedding,\n",
    "            start=1,\n",
    "            n_comp=5,\n",
    "            title='',\n",
    "            comp_names=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simlarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word1 = 'lawyer'\n",
    "word2 = 'lawyers'\n",
    "\n",
    "similarity(word1, word2, embedding, w2i, sim='angle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word = 'lawyers'\n",
    "closest(word, embedding, w2i, N=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "angles = word_angles(word, embedding, w2i)\n",
    "plt.hist(angles, bins=100)\n",
    "plt.xlabel('angles')\n",
    "plt.title('angles between %s and all other words' % word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explore loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_loading_df = top_loading_words_df(loadings, i2w, n=100)\n",
    "\n",
    "top_loading_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comp_numer = 100  # which loading\n",
    "n = 100 # how many components to show\n",
    "\n",
    "plt.figure(figsize=[40, 20])\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "top_loading_components(loadings[:, comp_numer], i2w, n, comp_numer)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(range(loadings.shape[0]), loadings[:, comp_numer], color='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
